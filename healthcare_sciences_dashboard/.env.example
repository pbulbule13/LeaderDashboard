# .env.example
# ===================================================================
# LLM CONFIGURATION - Priority Order
# ===================================================================
# Priority: DeepSeek → Gemini → OpenAI

# DeepSeek - Primary (Very affordable, good quality)
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_API_BASE=https://api.deepseek.com/v1

# Google Gemini - Secondary (Backup option)
GOOGLE_API_KEY=your_google_api_key_here

# OpenAI - Tertiary (Most capable, best quality)
OPENAI_API_KEY=your_openai_api_key_here

# Active Models (Using DeepSeek)
MODEL_NAME=deepseek-chat
TAB_QA_MODEL=deepseek-chat
RESPONSE_MODEL=deepseek-chat

# Fallback Models (tried in order if primary fails)
FALLBACK_MODELS=gemini-1.5-flash,gpt-4o,gpt-3.5-turbo

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/healthcare_sciences_db

# HEALTHCARE Sciences APIs (mock for now)
HEALTHCARE_SCIENCES_API_URL=https://api.healthcaresciences.internal
HEALTHCARE_SCIENCES_API_KEY=your_api_key_here

# Stock API
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_key
# or
POLYGON_API_KEY=your_polygon_key

# Application
DEBUG=True
LOG_LEVEL=INFO
PORT=8000
EOL

# Copy to .env and fill in your actual keys
cp .env.example .env